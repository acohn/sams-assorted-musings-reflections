Course SMURFs
=============

*Topics/tags: [Teaching](index-teaching), assessment, silly, short*

The other day, our department was
divvying up [the various tasks for members of our
department](http://www.cs.grinnell.edu/drupal6/departmental-tasks-2018-2019).
We got to the position of "evaluation coordinator" and started discussing
the tasks associated with that role.  I suggested that our coordinator
might encourage the faculty in the department to develop a list of
goals or outcomes for each class.  As I was saying that, I realized I
had forgotten what term is currently in vogue [1] , so I said something
like "goals, outcomes, SMURFs, whatever we call them these days" [2].
Unfortunately, one of my colleagues asked me to explain the acronym.
I admitted that I'd made up the acronym on the spur of the moment, but I
also attempted to come up with an explanation for the acronym.  I'm not
quite sure what I said at the time, but I've decided that a SMURF is a
"Specific, Measurable, Useful, Relevant Factor" for the class.  That is,

SMURFs are *Specific*.  When writing a SMURF, you should focus on the
details of the class, rather than general issues.  Not "I will teach
my students how to think algorithmically", which is a broad concept,
but "My students will learn how to use conditionals, loops, and
sequencing to develop and express algorithms formally".  Not "I will
teach my students to write better" but "My students will learn how
to use the twenty basic sentence patterns [3] to vary their writing
and therefore write more clearly and compellingly [4].

SMURFs are *Measurable*.  What's the point of a student learning something
that you can't measure? [5]

SMURFs are *Useful*.  That is SMURFs represent course factors that are 
useful to you or the students [6] in understanding 

Finally, SMURFs are *Relevant*.  That could mean that they are relevant to the
particular class. It could suggest that they are relevant to the student.
It could even imply that they are relevant to society.  I'll let you choose
your own interpretation.

And there you have it.  A brand new tool for reflecting on your classes.
Don't forget to include your course SMURFs before submitting that syllabus
to the Dean's office.

---

Postscript: While I did not spend deep thought on the five letters of
the acronym, I did come up with other possibilities.  "S" could stand for
"Significant" rather than "Specific".  After all, no one wants to
deal with insignificant factors.  "S" could also stand for a different
sense of "specific", specific to the class, rather than applicable to
other classes.  "M" could stand for "Meaningful".  We would, of course,
like our students to find meaning in what they learn and our faculty
to find meaning in what they teach.  But measurement seems to be at
the heart of requirements to list goals and outcomes [7].  Hence, I
felt it best to include some word meaning "measurable" in the acronym.
"Measurable" is almost certainly the best choice.  "U" could stand for
"Unique".  Like the second sense of "specific", "Unique" suggests that
the SMURF is tied to the particular course.  Finally, "R" could stand for
"Required".  That is, we should focus on the learning factors we expect
for every student, not just for some.

What about the "F"?  "Factor" is the only term that came to mind.

---

Postscript: While Smurf is undoubtedly a registered trademark, SMURF is
not.  Trademarks only apply to particular domains (trades).  I don't think 
learning factors interfere with children's toys or the animated films
that advertise those toys.

---

[1] Yes, I realize that there's a difference between learning goals
and learning outcomes.  Goals tend to be a bit more abstract (e.g.,
"You will learn recursion" while outcomes tend to be more concrete and
detailed "You will be able to use recursion in solving moderate-sized
problems that require you to do something with each element of a list".
One of the reasons that I listed both "goals" and "outcomes" is that I
can never remember whether we want both are only one.

[2] No, I can't always explain the things that my brain comes up with
in the spur of the moment.

[3] A few of my colleagues use _The Art of Styling Sentences_, which
describes twenty basic sentence patterns.

[4] In truth, I would not recommend the latter.  In every class that
I've taught, I've found that the students exhibit different levels of
writing ability; what I help one student with might be different than
what I'd help another with.  In point of fact, I consider "My students
will learn to write better" a fine factor.

[5] I believe that we do and should teach things that we cannot easily
measure.  I'm just echoing the repeated calls from our Dean's office for
"measurable outcomes".  Too many of the things that I care about don't
have natural measures and, in any case, the measures are often
different for different students.  I've already mentioned writing.
How do you easily quantify the growth in writing we see in students
over the semester?  We should not measure sentence length or rely on
computational "readability" metrics that typically ignore issues we
care about, like style.  

It's not just writing.  One of the goals of my introductory class is to
get students used to working with people who think differently than they
do and who may even have a different level of knowledge.  How do I measure
the transformation I see in a student who begins the semester asking,
"I don't want other students to slow me down, can I just do everything on
my own?" and ends the semester as a fierce advocate of pair programming?

[6] Or, I suppose, the Dean's office or external evaluators.

[7] And SMURFs.

---

*Version 0.1 of 2018-09-06.*
