A brief history of Grinnell's end-of-course evaluations
=======================================================

*Topics/tags: [Miscellaneous](index-misc), assessment, Grinnell*

Grinnell is considering significant changes to our
end-of-course-evaluation (EOCE [1]) system.  Why?  Well, the Faculty
were told, approximately, "If we don't make a change, the system will
break and we will lose all of the historical data [2]".  While it's not
true that we will lose all of the historical data [3], it is true that
we need need to think about a new approach to gathering and analyzing
data and, perhaps, revisit the status of Grinnell's EOCE system.

We know that EOCEs are biased [5].  That is, there are a wealth of
published studies that show bias in end-of-course evaluations, from
different numeric ratings to very different word choice based on race,
gender, and gender identity.  The growth of online courses has even
allowed researchers to eliminate many potentially confounding variables.
For example, since students don't see the professor, you can have a person
teach two online sections and identify them as male in one section and
female in the other [6,7].  Hence, I hope that considerations of bias
will be central to any discussions we have of EOCEs.

I also hope that we'll discontinue the optimistic myth that "EOCEs can be
used for both evaluation and development".  I'm sorry, but as a faculty
member, I want students to treat those situations very differently.
If I'm using my EOCEs to improve my teaching, I'd like students to think
primarily about things that need improvement.  And if their focus is
"Things Sam can do better", they will naturally give lower numeric scores.

Given that it's nearly twenty years since the Faculty agreed to impose
EOCEs on ourselves, I thought it would be useful to put together
a somewhat brief history of end-of-course evaluations at Grinnell.
At least that was the original plan for this piece.  Since it's me,
I can't resist adding a bit of commentary throughout [8].

When I came to Grinnell ...

Proposal was first presented in March 15, 1999 faculty meeting.  That was to set up the new system and experiment with it, with another followup in 1999-2000.  Lee suggested that we have students add a short, narrative answer.  (Wow, lee was already an Associate Professor in 1999.)

It looks like the next proposal from Elizabeth Dobbs was November 1, 1999.  That proposal was for another study, to be reviewed in 2000-2001.

November 20, 2000.  Bill Ferguson led us in a discussion.

December 4, 2000.  Continued discussion.  Voted.  Here's the important text, taken from a November 16, 2000 memo from EC that was approved by the faculty.

"In the event of a review, department chairs and the Personnel Committee will receive summaries of the quantitative data (see attached sample).  Chairs should not attempt to summarize the entire body of text comments, but it is permissible to use text comments from student evaluations to clarify and interpret the numeric data."

September 17, 2007.  Eliza reviewed our suggested changes with the faculty.

October 1 2007.  Motion passed.

The Budget Committee for the faculty may receive the total number of responses and proportion of those responses in the agree and strongly agree categories for questions #2 and #6 on the end-of-course evaluations for each course taught by faculty members under review. For comparative purposes, the Budget Committee may receive appropriate aggregate data for the faculty as a whole.

What does that all mean?  There are limits on what different committees can get.
Personnel can get scores and only the text that faculty or their review chairs
choose to release.  Budget committee can get summary info on categories 2 and 6
and *should* get comparative data.

---

[1] I use EOCE.  Almost everyone else uses EOC.  I'm not sure why.

[2] Given that the system is written in Microsoft Access and is almost
twenty years old, it's fairly certain that the system will break.

[3] And, not so surprisingly, discussions founded on sensationalistic
misstatements [4] don't tend to be as successful or useful.

[4] I was tempted to write "lies".  But that seems excessive, and also
doesn't tend toward open discussion.

[5] By "We", I mean anyone in the academy who has been paying
attention.  Unfortunately, it does not seem to mean everyone, and
does not necessarily include those making policies about EOCEe.

[6] I do not know of studies that explore what happens with people who
do not identify on the gender binary.  Nonetheless, given the other
biasing effects we see, the initial assumption should be that EOCE
scores will be biased against such people.

[7] I can't find the study I'm thinking of right now.  But I did find
an article that looks at gender differences in the same online course.

Mitchell, K., & Martin, J. (2018). [Gender Bias in Student Evaluations](https://www.cambridge.org/core/journals/ps-political-science-and-politics/article/gender-bias-in-student-evaluations/1224BE475C0AE75A2C2D8553210C4E27). _PS: Political Science& Politics_, 51(3), 648-652. doi:10.1017/S104909651800001X

[8] As you've already seen.

---

*Version 0.3 of 2018-10-20.*

