Developing an alternate end-of-course evaluation
================================================

*Topics/tags: [Grinnell](index-grinnell), assessment*

*This is a __draft__ of a [musing of the same name](alternate-eoces-2018-05-16) that got posted a week later.  I've left the draft around because it has some annotations.*

Grinnell, like many institutions, asks students to evaluate each course
at the end of the semester.  In my first few years at Grinnell, the
faculty voted to institute a common form for end-of-course evaluations
(EOCEs); prior to that, each department used their own form [1].
We still use paper forms.  I'm pretty sure that's a good thing [2].
From what I understand from the popular academic press, students become
even more biased against women and people of color when filling out
online-evaluations.

The EOCEs we use now are essentially identical to the EOCEs we developed
twenty years ago.  They ask six Likert-style questions [3,4].

1. The course sessions were conducted in a manner that helped me to understand the subject matter of the course.

2. The instructor helped me to understand the subject matter of the course.

3. Work completed with and/or discussions with other students in this course helped me to understand the subject matter of the course.

4. The oral and written work, tests, and/or other assignments helped me to understand the subject matter of the course.

5. Required readings or other course materials helped me to understand the subject matter of the course.

6. I learned a lot in this course.

But it's been nearly twenty years since we developed the form.  Is it perhaps
time to develop a different one?  

One thing that got me thinking about this issue was a recent
presentation about one of the important co-curricular
activities on campus.  In exploring the value of those
activities, they asked questions about [the College-wide learning
outcomes](https://www.grinnell.edu/academics/centers/ctla/college-wide).
Their slides said things like

> 82% agree or strongly agree that _this activity_ has helped them
  develop **the ability to communicate clearly and effectively**

I was happy to see that they reported categorical data in a sensible way.
It's much better than what the institution does with the EOCE data [4].

I've decided to conduct an experiment, mostly for my own purposes.  This
semester, when I distribute the official forms, I'm also going to distribute
some unofficial forms.  These unofficial forms will replace the current
Likert-style statements with the following.

1. This course helped me develop creative thinking skills.

2. This course helped me develop critical thinking skills.

3. This course helped develop my ability to communicate clearly and effectively.

4. This course helped me develop a sense of social responsibility and fairness.  
5. This course helped me develop the ability to continue to learn individually.

6. This course helped me develop the ability to continue to learn collaboratively.

7. This course helped me develop the ability to approach a question from multiple perspectives.

I realize that they probably need some tuning.  But they seem to be a
good starting point.

I'm trying to decide whether I should add a few other questions.  There
are two questions that I sometimes ask.

1. What is something you would recommend that we change about the course?

2. What is something that worked well and that we should keep doing in
this course?

There are also two questions that Jerod normally asks.

1. The one thing that most helped my learning was ...

2. One thing that would have helped my learning more is â€¦

I'm also tempted to ask how many hours they spent on the course.  Maybe
I'll just have them report that on the main form.

We'll see.  I'll report back on my results in a few weeks, after I've
turned in grades and received my offical and unoffical EOCEs.

---

Postscript: About fifteen years ago, I wrote [a long
essay about end-of-course evaluations for
students](http://www.cs.grinnell.edu/~rebelsky/about-eoc.html).  I'll
almost certainly rewrite that essay, not least because it is no longer
completely accurate.

---

[1] I always remind people that Math/CS/Stats,
the department that most reflected knowledge of
[quantitative-reasoning](unpacking-quantitative-reasoning), asked
primarily qualitative questions; the one quantitative question was
"About how many hours per week did you spend on this class?"

[2] I realize that not all students can read or fill out a paper form.
We do provide an electronic alternative for students who need those
kinds of accommodations.

[3] When we evaluate faculty, we tend to look at questions 2 and 6.

[4] A "Likert-style question" is one in which students respond to statements
with degrees of agreement or disagreement.  On these forms, I think it's
Strongly Agree, Moderately Agree, Slightly Agree, Slightly Disagree,
Moderately Disagree, and Strongly Disagree.

[5] I still don't understand why people consider it appropriate to assign
numbers to the agreement and disagreement and then do things like average
them.  Is Strongly Agree really twice as good as Slightly Disagree?

---

*Version 0.5 written 2018-05-08.*

*Version 1.0 of 2018-05-16.*
